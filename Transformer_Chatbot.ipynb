{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnaZmLYeVcoIW35D/np20C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaeGwon-Lee/Flex_Study/blob/main/Transformer_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sJ9ipFBLheX"
      },
      "source": [
        "## 1. 데이터 로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0blPz8DVoQ-"
      },
      "source": [
        "#### 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0zqKcrTEtv_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re                    # re (regular expression) : 정규 표현식 지원\n",
        "import urllib.request\n",
        "import time\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-L_0KuhGFIY_",
        "outputId": "623d8d0e-43bf-4255-ee65-ae5de55321cc"
      },
      "source": [
        "urllib.request.urlretrieve('https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv', filename='ChatBotData.csv')\n",
        "train = pd.read_csv('ChatBotData.csv')\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Q            A  label\n",
              "0           12시 땡!   하루가 또 가네요.      0\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "4          PPL 심하네   눈살이 찌푸려지죠.      0"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZJS5kNCFk63",
        "outputId": "d5cb8c07-d3f4-43f3-de87-6dc8ad47733e"
      },
      "source": [
        "len(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11823"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBRz334pFm2N",
        "outputId": "12c424a3-ea03-4ac8-cbee-c1d600238f0c"
      },
      "source": [
        "train.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Q        0\n",
              "A        0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRcjvfrUGlwO",
        "outputId": "440db749-4f8a-4ec0-92fb-0bd295a98c77"
      },
      "source": [
        "train['label'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EsR-K6uL40n"
      },
      "source": [
        "#### 구두점 구분"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH7JBIILGRB-"
      },
      "source": [
        "- 학습 기반의 토크나이저 사용  \n",
        "- 구두점(특수기호) 앞에 공백을 추가해서 다른 문자들과 구분  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s2QafwLF-yG"
      },
      "source": [
        "questions = []\n",
        "for sentence in train['Q']:\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1\", sentence)    # re.sub(정규표현식(패턴), 교체할 문자열, 문자열) : 문자열 바꾸기\n",
        "                                                     # 문자열 앞에 r이 붙으면 해당 문자열이 구성된 그대로 문자열로 반환 ex) 'abc\\n' -> abc / r'abc\\n' -> abc\\n\n",
        "                                                     # \\1 : 정규표현식에서의 첫번째 ( )\n",
        "  sentence = sentence.strip()                        # strip : 양쪽 문자열 및 공백 제거\n",
        "  questions.append(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCyUXlJBKg9A"
      },
      "source": [
        "answers = []\n",
        "for sentence in train['A']:\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1\", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  answers.append(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzh8fLIHLKfl",
        "outputId": "431a3e99-4641-4f0d-9826-6afc88df8b7c"
      },
      "source": [
        "print(questions[:5])\n",
        "print(answers[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
            "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHYYYXNHLkd9"
      },
      "source": [
        "## 2. 단어 집합 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGRxq40vLQIA"
      },
      "source": [
        "# 서브워드텍스트인코더 : 자주 사용되는 서브워드 단어로 토큰을 분리하는 토크나이저로 학습 데이터를 학습하여 서브워드로 구성된 단어 집합 생성\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KheRpp4TMk3_"
      },
      "source": [
        "# 시작 토큰과 종료 토큰 번호 설정\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "# 시작 토큰과 종료 토큰을 포함한 단어 집합 크기 설정\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLPRdGVUN72o",
        "outputId": "2d51469b-cf59-4818-ef77-ec210d003cc1"
      },
      "source": [
        "print('SOS :', START_TOKEN)\n",
        "print('EOS :', END_TOKEN)\n",
        "print('단어 집합 크기 :', VOCAB_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SOS : [8176]\n",
            "EOS : [8177]\n",
            "단어 집합 크기 : 8178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL53yB_nOW6n"
      },
      "source": [
        "## 3. 정수 인코딩과 패딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgpVrUOuPxSO"
      },
      "source": [
        "#### 정수 인코딩 예시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEWqzBAuP_Mu"
      },
      "source": [
        "sample_string = questions[20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrvh5CFrP7AH",
        "outputId": "f56a84e7-e9aa-4167-869a-ef8d96623f1c"
      },
      "source": [
        "tokenized_string = tokenizer.encode(sample_string)\n",
        "print('정수 인코딩 후의 문장 : {}'.format(tokenized_string))\n",
        "\n",
        "original_string = tokenizer.decode(tokenized_string)\n",
        "print('기존 문장 : {}'.format(original_string))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정수 인코딩 후의 문장 : [5765, 610, 3507, 141, 684, 3745, 848]\n",
            "기존 문장 : 가스비 비싼데 감기 걸리겠어\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnXrsqcxQgch",
        "outputId": "e777e715-5873-490e-93b9-3fcf4ad0d9c6"
      },
      "source": [
        "for ts in tokenized_string :\n",
        "  print('{} ---> {}'.format(ts, tokenizer.decode([ts])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5765 ---> 가스\n",
            "610 ---> 비 \n",
            "3507 ---> 비싼\n",
            "141 ---> 데 \n",
            "684 ---> 감기 \n",
            "3745 ---> 걸리\n",
            "848 ---> 겠어\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNN7fQL0Q6pf"
      },
      "source": [
        "이탤릭체 텍스트#### 정수 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofzFoY31QyGX"
      },
      "source": [
        "MAX_LENGTH = 40\n",
        "\n",
        "def tokenize_and_filter(inputs, outputs) :\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs) :\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    tokenized_inputs.append(sentence1)\n",
        "    tokenized_outputs.append(sentence2)\n",
        "\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(tokenized_outputs, maxlen=MAX_LENGTH, padding='post')    # padding='post' : 끝 부분에 패딩\n",
        "\n",
        "  return tokenized_inputs, tokenized_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JhuGsajUVHH"
      },
      "source": [
        "questions, answers = tokenize_and_filter(questions, answers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3iN0WrmU5hY",
        "outputId": "2d16bd62-a0ea-4092-9a2b-c65e98d65a40"
      },
      "source": [
        "questions.shape, answers.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11823, 40), (11823, 40))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC15cbieVDme",
        "outputId": "9e5ba96c-91ef-47b1-bbbd-aa8c773fe924"
      },
      "source": [
        "questions[0], answers[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([8176, 7914, 4205, 3058,   41, 8177,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0], dtype=int32),\n",
              " array([8176, 3842,   74, 7893,    1, 8177,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0], dtype=int32))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9G0eJ9tVO94"
      },
      "source": [
        "## 4. 인코더와 디코더의 입력, 레이블 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll5k1gMNVJj2"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1]    # 디코더 입력 : 마지막 패딩 토큰 제거\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]    # 시작 토큰 제거\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()    # cache : 데이터셋을 메모리 또는 로컬 저장소에 캐시\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)    # prefeth : 데이터 로드 시간을 줄이기 위해 미리 메모리에 적재시킴(얼마만큼)\n",
        "                                                             # AUTOTUNE : 병렬처리 수준 위임"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM3NJIvwRlRp",
        "outputId": "57de962e-9b60-44e2-906f-0aca60ff9df9"
      },
      "source": [
        "print(answers[0])\n",
        "print(answers[:1][:, :-1])\n",
        "print(answers[:1][:, 1:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8176 3842   74 7893    1 8177    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "[[8176 3842   74 7893    1 8177    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]]\n",
            "[[3842   74 7893    1 8177    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciX-53WoR_al"
      },
      "source": [
        "## 5. 트랜스포머 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXktvu6QS9qY"
      },
      "source": [
        "#### 트랜스포머 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abs6XzTZT0Qb"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2*(i//2)) / tf.cast(d_model, tf.float32))    # tf.pow : 거듭제곱 / tf.cast : d_model 형태를 float으로\n",
        "    return position * angles\n",
        "  \n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)    # tf.newaxis : 차원을 늘려줌 ex) (4,) -> (4,1)\n",
        "    \n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])    # 0::2 : 0부터 끝까지 두 칸 간격으로\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])    # 1::2 : 1부터 끝까지 두 칸 간격으로\n",
        "\n",
        "    angle_rads = np.zeros(angle_rads.shape)\n",
        "    angle_rads[:, 0::2] = sines\n",
        "    angle_rads[:, 1::2] = cosines\n",
        "    pos_encoding = tf.constant(angle_rads)    # tf.constant : 상수 텐서 만들기\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "\n",
        "    print(pos_encoding.shape)\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "def call(self, inputs):\n",
        "  return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxl9KaAjTuV7"
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "\n",
        "  # 어텐션 스코어 행렬 (Q와 K의 곱)\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b = True)\n",
        "\n",
        "  # 스케일링\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # 마스킹 (어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값 넣기 => 소프트맥스 지나면 0이 됨)\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "  \n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)    # 어텐션 분포\n",
        "  output = tf.matmul(attention_weights, value)    # 어텐션 값\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6V-COvTTiGP"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name='multi_head_attention'):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0    # assert : 조건이 거짓일때 에러를 발생시킴\n",
        "    \n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    # W_q, W_k, W_v에 해당하는 밀집층 정의\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    # W_0에 해당하는 밀집층 정의\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0,2,1,3])    # perm : 차원의 순서\n",
        "                                                   # 여기선 (batch_size, self.num_heads, -1, self.depth)\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # 1. W_q, W_k, W_v에 해당하는 밀집층 지나기\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # 2. 헤드 나누기\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # 3. 스케일드 닷 프로덕트 어텐션\n",
        "    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)    # ( batch_size, num_heads, query의 문장 길이, d_model/num_heads )\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0,2,1,3])\n",
        "\n",
        "    # 4. 헤드 연결하기\n",
        "    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "\n",
        "    # 5. W_0에 해당하는 밀집층 지나기\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSoRxOy3VNCY"
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x,0), tf.float32)    # tf.cast : 형태를 float으로 / tf.math.equal : x == y의 truth value(TRUE or FALSE) 반환\n",
        "\n",
        "  # ( batch_size, 1, 1, key의 문장길이 )\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]    # tf.newaxis : 차원을 늘려줌 ex) (4,) -> (4,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6OZCe8jTh-5"
      },
      "source": [
        "def encoder_layer(dff, d_model, num_heads, dropout, name='encoder_layer'):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name='input')\n",
        "\n",
        "  padding_mask = tf.keras.Input(shape=(1,1,None), name='padding_mask')\n",
        "\n",
        "  attention = MultiHeadAttention(d_model, num_heads, name='attention')({\n",
        "          'query': inputs, 'key': inputs, 'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  \n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs,padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4--FdSBThyz"
      },
      "source": [
        "def encoder(vocab_size, num_layers, dff, d_model, num_heads, dropout, name='encoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "\n",
        "  padding_mask = tf.keras.Input(shape=(1,1,None), name='padding_mask')\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads, \n",
        "                            dropout=dropout, name='encoder_layer_{}'.format(i))([outputs, padding_mask])\n",
        "  \n",
        "  return tf.keras.Model(inputs=[inputs,padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn1dnfgQVZem"
      },
      "source": [
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)    # band_part 부분 : 아래 삼각형 부분을 1로 유지하고 나머지는 0으로 바꿈\n",
        "  padding_mask = create_padding_mask(x)    # 패딩 마스크도 포함\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6ObsFc5SkwI"
      },
      "source": [
        "def decoder_layer(dff, d_model, num_heads, dropout, name='decoder_layer'):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "\n",
        "  look_ahead_mask = tf.keras.Input(shape=(1,None,None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1,1,None), name='padding_mask')\n",
        "\n",
        "  attention1 = MultiHeadAttention(d_model, num_heads, name='attention_1')(inputs={\n",
        "      'query': inputs, 'key': inputs, 'value': inputs,\n",
        "      'mask': look_ahead_mask\n",
        "  })\n",
        "\n",
        "  attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(d_model, num_heads, name='attention_2')(inputs={\n",
        "      'query': attention1, 'key': enc_outputs, 'value': enc_outputs,\n",
        "      'mask': padding_mask\n",
        "  })\n",
        "\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "                        outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B5X80k3Skfl"
      },
      "source": [
        "def decoder(vocab_size, num_layers, dff, d_model, num_heads, dropout, name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "\n",
        "  look_ahead_mask = tf.keras.Input(shape=(1,None,None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1,1,None), name='padding_mask')\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
        "                            dropout=dropout, name='decoder_layer_{}'.format(i)\n",
        "                            )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "  \n",
        "  return tf.keras.Model(inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "                        outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK0tC3QZSkHe"
      },
      "source": [
        "def transformer(vocab_size, num_layers, dff, d_model, num_heads, dropout, name='transformer'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name='dec_inputs')\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1,1,None), name='enc_padding_mask')(inputs)\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask, output_shape=(1,None,None), name='look_ahead_mask')(dec_inputs)\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1,1,None), name='dec_padding_mask')(inputs)\n",
        "      \n",
        "  enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff, d_model=d_model,\n",
        "                        num_heads=num_heads, dropout=dropout)(inputs=[inputs, enc_padding_mask])\n",
        "  dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff, d_model=d_model,\n",
        "                        num_heads=num_heads, dropout=dropout)(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name='outputs')(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InCZccSvTEdX"
      },
      "source": [
        "#### 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYndmE8ASCm2",
        "outputId": "8335942f-9b04-4c04-fae9-5dc96d56dcc3"
      },
      "source": [
        "D_MODEL = 256\n",
        "NUM_LAYERS = 2\n",
        "NUM_HEADS = 8\n",
        "DFF = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dff=DFF,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 8178, 256)\n",
            "(1, 8178, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl0gpN__W2uE"
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5g1ngb1WyP7"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)    # tf.math.rsqrt : reciprocal of square root 제곱근의 역수 (-0.5 제곱)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jHTj2POUxdU"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH-1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRhbuqbAWX30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b74d19-7f78-4e2b-9f9c-323161ea3bd6"
      },
      "source": [
        "EPOCHS = 50\n",
        "model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "185/185 [==============================] - 32s 118ms/step - loss: 1.4661 - accuracy: 0.0306\n",
            "Epoch 2/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 1.1821 - accuracy: 0.0495\n",
            "Epoch 3/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 1.0029 - accuracy: 0.0507\n",
            "Epoch 4/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.9153 - accuracy: 0.0551\n",
            "Epoch 5/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.8461 - accuracy: 0.0594\n",
            "Epoch 6/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.7756 - accuracy: 0.0655\n",
            "Epoch 7/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.6979 - accuracy: 0.0739\n",
            "Epoch 8/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.6124 - accuracy: 0.0835\n",
            "Epoch 9/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.5219 - accuracy: 0.0941\n",
            "Epoch 10/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.4304 - accuracy: 0.1056\n",
            "Epoch 11/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.3422 - accuracy: 0.1178\n",
            "Epoch 12/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.2607 - accuracy: 0.1303\n",
            "Epoch 13/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.1916 - accuracy: 0.1409\n",
            "Epoch 14/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.1344 - accuracy: 0.1508\n",
            "Epoch 15/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.0918 - accuracy: 0.1585\n",
            "Epoch 16/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0645 - accuracy: 0.1631\n",
            "Epoch 17/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.0483 - accuracy: 0.1656\n",
            "Epoch 18/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.0416 - accuracy: 0.1664\n",
            "Epoch 19/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0372 - accuracy: 0.1668\n",
            "Epoch 20/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0352 - accuracy: 0.1671\n",
            "Epoch 21/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0333 - accuracy: 0.1674\n",
            "Epoch 22/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.0322 - accuracy: 0.1675\n",
            "Epoch 23/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0308 - accuracy: 0.1676\n",
            "Epoch 24/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.0252 - accuracy: 0.1691\n",
            "Epoch 25/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0234 - accuracy: 0.1695\n",
            "Epoch 26/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0205 - accuracy: 0.1702\n",
            "Epoch 27/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0178 - accuracy: 0.1709\n",
            "Epoch 28/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0155 - accuracy: 0.1715\n",
            "Epoch 29/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.0150 - accuracy: 0.1716\n",
            "Epoch 30/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.0136 - accuracy: 0.1719\n",
            "Epoch 31/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.0127 - accuracy: 0.1722\n",
            "Epoch 32/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0113 - accuracy: 0.1725\n",
            "Epoch 33/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.0105 - accuracy: 0.1727\n",
            "Epoch 34/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.0099 - accuracy: 0.1729\n",
            "Epoch 35/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0094 - accuracy: 0.1730\n",
            "Epoch 36/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0086 - accuracy: 0.1731\n",
            "Epoch 37/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.0081 - accuracy: 0.1732\n",
            "Epoch 38/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.0080 - accuracy: 0.1732\n",
            "Epoch 39/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0073 - accuracy: 0.1734\n",
            "Epoch 40/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0073 - accuracy: 0.1733\n",
            "Epoch 41/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0067 - accuracy: 0.1736\n",
            "Epoch 42/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0064 - accuracy: 0.1737\n",
            "Epoch 43/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0061 - accuracy: 0.1737\n",
            "Epoch 44/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0056 - accuracy: 0.1738\n",
            "Epoch 45/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0057 - accuracy: 0.1738\n",
            "Epoch 46/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0054 - accuracy: 0.1739\n",
            "Epoch 47/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0051 - accuracy: 0.1740\n",
            "Epoch 48/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0053 - accuracy: 0.1739\n",
            "Epoch 49/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0048 - accuracy: 0.1740\n",
            "Epoch 50/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0048 - accuracy: 0.1740\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb752e4b710>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRYcZWShXBwl"
      },
      "source": [
        "## 6. 챗봇 평가하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deKpQrpibFl_"
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I99hFfLRXBbX"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "  sentence = tf.expand_dims(START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "    \n",
        "  return tf.squeeze(output, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y2gNh_2ahUo"
      },
      "source": [
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "  predicted_sentence = tokenizer.decode([i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O2rT-kKbaAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "670ee553-30a8-4460-b8ff-19c477a59b6e"
      },
      "source": [
        "output = predict(\"영화 볼래?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 영화 볼래?\n",
            "Output: 최신 영화가 좋을 것 같아요 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-ol67JdbZ6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bc21487-6430-4d35-d3f9-d1ab15fcedb2"
      },
      "source": [
        "output = predict(\"고민이 있어\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 고민이 있어\n",
            "Output: 제가 들어드릴게요 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NITskUwbZy8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b42a260e-81f0-4de6-b808-f72589156c80"
      },
      "source": [
        "output = predict(\"너무 화가나\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 너무 화가나\n",
            "Output: 자신을 비난하지 마세요 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwL7rhWtbZih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19e05db6-3d81-4966-9ec4-9caa577bab6c"
      },
      "source": [
        "output = predict(\"게임하고싶당\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 게임하고싶당\n",
            "Output: 어서 충전 하세요 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etrlvdERbY7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ec3db47-8216-4a53-9ac5-a51f8c4b1ddb"
      },
      "source": [
        "output = predict(\"공부 해야하나?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 공부 해야하나?\n",
            "Output: 지금도 늦지 않았어요 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBek2qUFtJvm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}